\section{Desarrollo}
\label{sec:desarrollo}

\subsection{Algoritmo de Fuerza Bruta}

En ciencias de la computación, la técnica de búsqueda por fuerza bruta o búsqueda exhaustiva, también conocida como generate and test (generar y probar), es una forma muy general de resolver problemas y un paradigma de algoritmos que consiste en enumerar sistemáticamente todos los posibles candidatos a ser solución y luego chequear si cada candidato satisface o no el enunciado del problema. \footnote{$https://es.wikipedia.org/wiki/B\%C3\%BAsqueda\_de\_fuerza\_bruta$}

En nuestro problema "Problema de la Mochila (Gloppi Ya)"  dado un conjunto de pedidos con un peso y beneficio asociado y una mochila de capacidad fija, la solución consiste en el subconjunto de pedidos que maximice la suma de beneficios y a su vez no supere la capacidad de la mochila.

Siguiendo nuestro paradigma de resolución, deberíamos generar todas las posibles soluciones al problema y luego chequear si satisfacen el enunciado. Para ello, generaremos todos los subconjuntos de pedidos (posibles soluciones) y luego nos quedaremos con aquel que maximice la suma de beneficios y a su vez quepa en la mochila.


\begin{algorithm}
\caption{Fuerza Bruta}\label{selection}
\begin{algorithmic}[1]
\Procedure{bruteForce}{$vector \ \ pedidos, \ int \ \ w$}
	\State $vector \ subSets$
   \For{\textbf{$i \gets 1$ to} $2^{|pedidos|}$}
   	\State $wi \gets 0$
	\State $pi \gets 0$
    \For{\textbf{$j \gets 0$ to} $|pedidos|$}
    \If{$j-esimo\ bit\ de\ i\ esta\ en\ 1$}
    	\State $wi \gets wi\ +\ pedidos[j].beneficio$
	\State $pi \gets pi\ +\ pedidos[j].peso$
	\EndIf
	\EndFor

	\If{$wi \ > \ w$}
	\State $pi \gets -1$
	\EndIf

	\State $subSets[i] \gets pi $
    \EndFor
   	\State $Return \ \ maxElement(subSets)$
\EndProcedure
\end{algorithmic}
\end{algorithm}


Al comienzo de nuestra solución propuesta hacemos un ciclo el cual ira desde $1$ hasta $2^{n}$, es decir desde 1 hasta la cantidad de subconjuntos. Dentro de este ciclo haremos otro ciclo en n, la cantidad de elementos del conjunto (véase también como la cantidad de bits de $2^{n}$), y en el cual usaremos a la variable j como un numero binario, fijándonos que bits están en 1 para tener en cuenta esas posiciones del vector pedidos (considerando ese subconjunto) para sumar su beneficio y peso (correspondientemente acumulado en las variables wi y pi) y sea una posible solución(generando de esta manera, todos los subconjuntos posibles). Finalmente nos preguntamos si la suma de los elementos considerados supera la capacidad de la mochila, de ser así seteamos su beneficio en $-1$ (eliminando la solución), caso contrario almacenamos el beneficio total en el vector subSets. Y por ultimo retornamos el elemento de mayor valor del vector subSets, siendo este el mayor beneficio obtenible.

\subsection*{Análisis de Complejidad}
Describiremos cada acción con su complejidad y luego realizaremos la suma total.


Complejidad de calcular la suma de todos los elementos de los $2^{n}$ posibles subconjuntos de pedidos que pueden llegar a ser a lo sumo de longitud n = O($n*2^{n}$).


Complejidad de algunos checkeos y comparaciones de cantidades = O(1).


Complejidad Total del algoritmo = O($n*2^{n}$).

\subsection{Backtracking}

Backtracking es una técnica algorítmica que se encarga de encontrar todas las soluciones a un problema, construyendo de a pasos los candidatos a la solución. La ventaja por sobre los algoritmos de fuerza bruta proviene de que podemos eliminar un gran número de candidatos con un único test utilizando podas. Las mismas nos permiten determinar cuándo debemos abandonar a un candidato y que no es posible que alcancen una solución del problema.

Para aplicar backtracking a nuestro problema, lo que notamos es que dado un elemento, una solución puede contenerlo o no. De esta manera, queremos construir nuestro árbol de recurrencias (o árbol de backtracking) en dónde en el paso i, o bien incluímos al i-ésimo elemento en la solución parcial o bien lo excluímos. Esto nos lleva a generar un árbol que contiene a todos los subconjuntos posibles.

El siguiente pseudocódigo muestra como podemos obtener ésto facilmente:

\begin{algorithm}
\caption{Backtracking}\label{selection}
\begin{algorithmic}[1]
\Procedure{backtracking}{$pair \ \ res, \ pair \ \ parcial, \ int \ \ indice$}
   \For{\textbf{$i \gets indice$ to} $|pedidos|$}
   	\State $parcial.w \gets parcial.w + pedidos[i].w$
	  \State $parcial.b \gets parcial.b + pedidos[i].b$
    \If{parcial es mejor que res}
    \State $res \gets parcial$
    \EndIf
    \State Backtracking(res, parcial, i+1)
    \State $parcial.w \gets parcial.w - pedidos[i].w$
	  \State $parcial.b \gets parcial.b - pedidos[i].b$

	 \EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

Veamos bien como funciona el algoritmo. Las variables res y parcial representan a la solución final y a la solución parcial que estamos estudiando respectivamente, miesntras que índice es el elemento que tenemos que decidir si agregar o no a nuestro candidato. El llamado inicial va a tener a res y a parcial como los pares <0,0>, e índice comenzará en 0. El for recorre todos los elementos que quedan por visitar en un llamado dado (desde índice hasta el final del arreglo de pedidos). En este  ciclo, primero agregamos el elemento a nuestra solución parcial. Si ahora parcial es mejor que res, actualizamos res. Luego, realizamos el llamado recursivo aumentando el índice para recorrer los caminos que incluye al elemento i. Por último, sacamos al elemento i de parcial y continuamos con la próxima iteración, obteniendo así los caminos que no incluyen al elemento i.


Analicemos la complejidad de éste algortimo. Como mencionamos antes, para cada elemento tenemos la decisión de incluirlo o no en nuestra solución parcial. Ésto nos lleva a obtener un árbol binario completo de altura igual a la cantidad de elementos. En otras palabras, tenemos $2^{n}$ caminos de longitud n. Para armar cada camino, fuimos agregando nodos con un costo de O(1), lo que deriva en un costo total de O($2^{n} * n$) para armar todo el árbol de backtracking.

Sin embargo, ésta implementación no aprovecha el uso de podas para poder descartar rápidamente un conjunto de candidatos que no pueden ser la solución final. Para mejorar sobre ésto, vamos a utilizar dos tipos de podas:

\begin{itemize}
\item Poda por factibilidad: éste tipo de podas consiste en descartar una solución parcial que sin importar como continúe su recorrido, no puede cumplir con las condiciones necesarias para ser solución del problema. En nuestro caso, nos fijamos que si un subconjunto tiene un peso mayor al límite W, ya no tiene sentido seguir con el recorrido. Esto nos dejar sin explorar todo el subárbol del candidato podado. Ésta técnica podría ser particularmente útil si los elementos nos viniesen ordenados de mayor a menor por su peso. Así, las soluciones que se pasan del límite W lo harían en menos pasos, permitiendonos podar más candidatos.
\item Poda por optimalidad: Cuando no solo importa obtener una solución, si no que buscamos una solución óptima, podemos aplicar éste tipo de podas. Si estamos construyendo un candidato que no tiene posibilidades de ser mejor que la mejor solución encontrada hasta ahora, detenemos el recorrido. En nuestro problema, podemos aplicar una poda de éste tipo sabiendo en cada paso, cuál es el beneficio máximo que podemos agregar a nuestra solución. Si incluso sumando todo ese beneficio no podemos llegar al de nuestra mejor solución, nos detenemos.
\end{itemize}

Notemos que ninguna de estas podas agrega complejidad a nuestro algoritmo original. Para implementar la poda por factibilidad, alcanza con hacer un chequeo de si nuestro peso parcial es mayor al límite W antes de hacer el llamado recursivo. Por otro lado, si mantenemos una variable con la suma de los beneficios de todos los elementos que aún no visitamos, alcanza con que realizemos otro chequeo antes del llamado recursivo, y que vayamos decrementando el beneficio total en cada paso. Cada una de estas cosas tiene una complejidad de O(1).


\subsection{Algoritmo Meet in the Middle}

La técnica de Meet in the Middle nos permite partir el problema en dos partes de tamaño similar, y luego combinar sus resultados de manera eficiente.
El esquema general de esta técnica es el siguiente:

\begin{enumerate}
\item Partir el problema en dos partes del mismo tamaño.
\item Resolver cada parte por separado, utilizando la técnica de fuerza bruta.
\item Combinar los resultados.
\item Devolver el resultado.
\end{enumerate}

Notemos que si queremos obtener una buena complejidad usando esta técnica, el paso 3) es dónde debemos detenernos con más cuidado. Si no combinamos cuidadosamente los resultados, podríamos obtener una complejidad peor que con fuerza bruta.
Veamos como se aplica éste esquema a nuestro problema:

\begin{enumerate}
\item Separamos todos nuestros elementos en 2 mitades.
\item Para cada mitad, calculamos los pesos y beneficios de todos los subconjuntos posibles.
\item Para cada subconjunto de la primera mitad, buscamos el subconjunto de la segunda mitad tal que se maximize nuestro beneficio.
\item Devolvemos el par con mayor beneficio.
\end{enumerate}

Detengamonos en el paso 3) y veamos la complejidad de éste algoritmo. Sabemos que calcular todos los subconjuntos de un conjunto de cardinal n cuesta O($2^{n}$). En nuestro caso, tenemos dos subconjuntos de cardinal n/2, por lo que la complejidad de los primeros dos pasos es de O($2^{n/2}$). \\
Para implementar el paso 3) hacemos lo siguiente:
\begin{itemize}
\item Ordenamos la segunda mitad según su peso de menor a mayor, y según su beneficio de mayor a menor. Esto tiene una complejidad de O($2^{n/2} * log(2^{n/2})$) = O($2^{n/2} * n/2$).
\item Filtramos la segunda mitad, descartando todos los subconjuntos cuyo peso es mayor al de otros con beneficio mayor o igual. Debido a como ordenamos la segunda mitad, podemos filtrarla en orden lineal, es decir, O($2^{n/2}$).
\item Usamos búsqueda binaria para aparear subconjuntos de cada mitad. La complejidad de esto es la de hacer una búsqueda binaria en un arreglo de tamaño $2^{n/2}$ para $2^{n/2}$ elementos, es decir, O($2^{n/2} * log(2^{n/2})$) = O($2^{n/2} * n/2$).
\end{itemize}

\bigskip

Por lo tanto, vemos que la complejidad total del algoritmo es de O($2^{n/2} * n$).

\subsection{Algoritmo de Programación Dinámica}
La programación dinámica es un método para reducir el tiempo de ejecución de un algoritmo mediante la utilización de subproblemas superpuestos y subestructuras óptimas\footnote{Una subestructura óptima significa que se pueden usar soluciones óptimas de subproblemas para encontrar la solución óptima del problema en su conjunto.}.

Los subproblemas se resuelven a su vez dividiéndolos en subproblemas más pequeños hasta que se alcance el caso base, donde la solución al problema es trivial.


En resumen, la programación dinámica hace uso de:
\begin{itemize}
	\item Subproblemas superpuestos
	\item Subestructuras óptimas
	\item Memoización (almacenar los resultados obtenidos para no recalcularlos)
\end{itemize}


Ademas, la programación dinámica toma normalmente uno de los dos siguientes enfoques:
\begin{itemize}
	\item Top-down: El problema se divide en subproblemas, y estos se resuelven recordando las soluciones por si fueran necesarias nuevamente. Es una combinación de memoización y recursión.
	\item Bottom-up: Todos los problemas que puedan ser necesarios se resuelven de antemano y después se usan para resolver las soluciones a problemas mayores. Este enfoque es ligeramente mejor en consumo de espacio y llamadas a funciones, pero a veces resulta poco intuitivo encontrar todos los subproblemas necesarios para resolver un problema dado.
\end{itemize}


Para nuestro problema en particular podemos plantear la siguiente función matemática recursiva:

\begin{equation*}
f(i,j) = "el\ maximo\ beneficio\ obtenible\ dados\ i\ pedidos\ (con\ su\ respectivo\ peso\ y\ beneficio)\ y\ una\ mochila\ con\ capacidad\ j"
\end{equation*}

\begin{equation*}
	f(i,j) = \begin{cases} 
          0 & i = 0 \lor j = 0 \\
          max(f(i-1,j), beneficio[i-1] + f(i-1, j-peso[i-1])) & peso[i-1] \leq j \\
          f(i-1, j) & en\ otro\ caso
       \end{cases}
\end{equation*}

Exhibimos el algoritmo propuesto para mostrar como hacemos uso de la técnica de memoizacion y no tener que recalcular valores anteriormente calculados.

\begin{algorithm}
\caption{Programacion Dinamica}\label{selection}
\begin{algorithmic}[1]
\Procedure{dp}{$vector \ \ pedidos, \ int \ \ w$}
	\State $int \ dp[n+1][w+1]$
   	\For{\textbf{$i \gets 0$ to} $|pedidos|$}
    		\For{\textbf{$j \gets 0$ to} $w$}
    			\If{$i = 0\ \ j=0$}
    				\State $dp[i][j] \gets 0$
    			
    			\Else
				\If{$pedidos[i-1].peso \leq j$}
					\State $dp[i][j] \gets max(dp[i-1][j], pedidos[i-1].beneficio + dp[i-1][j-pedidos[i-1].peso])$
				\Else
					\State $dp[i][j] \gets dp[i-1][j]$
				\EndIf
			\EndIf
		\EndFor
    \EndFor
   	\Return maxElement(subSets)
\EndProcedure
\end{algorithmic}
\end{algorithm}

%				if(pedidos[i-1].first <= j){
%					dp[i][j] = max(dp[i-1][j], pedidos[i-1].second + dp[i-1][j-pedidos[i-1].first]);
%				}else{
%					dp[i][j] = dp[i-1][j];
%				}